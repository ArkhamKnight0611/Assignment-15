{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yJRQcwjuiTIA"
      },
      "outputs": [],
      "source": [
        "# Web scraping is the process of using bots to extract content and data from a website.\n",
        "# Web scraping is used in a variety of digital businesses that rely on data harvesting. Legitimate use cases include:\n",
        "\n",
        "# Search engine bots crawling a site, analyzing its content and then ranking it.\n",
        "# Price comparison sites deploying bots to auto-fetch prices and product descriptions for allied seller websites.\n",
        "# Market research companies using scrapers to pull data from forums and social media (e.g., for sentiment analysis)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Web scraping libraries are software packages that provide pre-built functions and tools for web scraping tasks.\n",
        "# These libraries simplify the process of navigating web pages, parsing HTML data, and locating elements to extract.\n",
        "\n",
        "# A web scraping tool is a software or program that automatically gathers data from web sources.\n",
        "# Depending on several factors, such as your organizationâ€™s unique requirements, resources, and technical expertise, you can use an in-house or outsourced web scraper\n",
        "\n",
        "\n",
        "# Web scraping APIs enable developers to access and extract relevant data from websites.\n",
        "# Websites can provide web scraping APIs, such as Twitter API, Amazon API, and Facebook API.\n",
        "# However, some websites may not offer  APIs for the targeted data, requiring the use of a web scraping service to collect web data.\n",
        "# API may be more cost-effective than web scraping."
      ],
      "metadata": {
        "id": "PqhZ-C1qifti"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Beautiful Soup: Specifically designed for parsing and extracting web data from HTML and XML sites.\n",
        "# You can use Beautiful Soup to collect data from static websites that do not require JavaScript to load."
      ],
      "metadata": {
        "id": "3YMnCzXijn4T"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flask is a lightweight framework to build websites. We'll use this to parse our collected data and display it as HTML in a new HTML file.\n",
        "# The requests module allows us to send http requests to the website we want to scrape.\n",
        "# The first line imports the Flask class and the render_template method from the flask library."
      ],
      "metadata": {
        "id": "R-1eNnA5jy5R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AWS CodePipeline is a continuous delivery service you can use to model, visualize, and automate the steps required to release your software. You can quickly model and configure the different stages of a software release process.\n",
        "# CodePipeline automates the steps required to release your software changes continuously.\n",
        "\n",
        "# AWS Elastic Beanstalk is an orchestration service offered by Amazon Web Services for deploying applications which orchestrates various AWS services, including EC2, S3, Simple Notification Service, CloudWatch, autoscaling, and Elastic Load Balancers.AWS Elastic Beanstalk is an orchestration service offered by Amazon Web Services for deploying applications which orchestrates various AWS services, including EC2, S3, Simple Notification Service, CloudWatch, autoscaling, and Elastic Load Balancers."
      ],
      "metadata": {
        "id": "cCwTbahuj-jm"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}